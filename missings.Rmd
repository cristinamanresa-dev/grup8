---
title: "preprocessing missings"
author: "Laia ribes"
date: "2025-10-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Llegim les dades

```{r}
train <- read.csv("train_AED.csv")
test <- read.csv("test_AED.csv")
```

tot el apartat del little test ens el podem estalviar ja que esl NA's en les nostres dades estan distribuits completament aleatoriament i per tant no es pot arribar a calcular la matriu de covariancies

# 4.3 patrons descriptius dels na 

```{r}
library(visdat)
library(ggplot2)
library(naniar)

vis_dat(train);
vis_miss(train)
```

amb aixo podem observar que no hi ha cap linia on siguin tot missings, per tant no fa falta eliminar cap fila 

(el codi del ggplot no ens funciona i per tant no el durem a terme)

## visualitzacio dels na per variables 

```{r}
gg_miss_var(train) + labs(y = "Look at all the missing ones")
```
veiem que totes les variables contenen el mateix nombre de missings

## deteccio dels nas en la base de dades 

```{r}
train_shadow <- bind_shadow(train)
```


aixo no ens dona cap mena de conclusio ni informacio ja que hi veiem molts na 
```{r}
library(dplyr)
train %>%
  bind_shadow() %>%
  group_by(speechiness) %>%
  summarise_at(.vars = "loudness",
               .funs = c("mean", "sd", "var", "min", "max"),
               na.rm = TRUE)
```

```{r}
str(train)
```

si ho fem amb alguna variable numerica no ens donara be, s'ha de fer amb una variable factor
```{r}
ggplot(train_shadow,
       aes(x = song_popularity,
           colour = speechiness_NA)) + 
  geom_density()
```

La distribució de popularitat entre cançons amb i sense valor d’‘instrumentalness’ és pràcticament idèntica. Per tant, els valors perduts no semblen associats a cançons amb comportaments diferents en termes de popularitat, cosa que apunta a una absència de biaix rellevant (possibles MCAR o MAR febles)

## extreu estadistiques amb nas de las base de dades

(aquest apartat com que no se ben be quines conclusions en podem treure no lhe fet)


# imputació per MICE

```{r}
train <- read.csv("train_AED.csv")
```

Eliminamos las variables categoricas

```{r}
# Manté només les variables numèriques
train_numeric <- train[, sapply(train, is.numeric)]
summary(train_numeric)

quiCat <- which(lapply(train, class) %in% c("character", "factor"))
(categories <- names(train)[quiCat])
#train2 <- subset(train, select = -c(get(categories))) # AQUI SURT UN ERROR
#summary(train2)
```

visualitzem els patrons dels nas 
```{r}
par(mfrow = c(1, 1))
mice::md.pattern(train_numeric, rotate.names = TRUE)
```
*surt el grafic molt extrany*

a continuacaio realitzezm imputacio dels valors faltants de manera multivariada

```{r}
imputed_Data <- mice::mice(train_numeric, m=5, maxit = 50, method = 'pmm', seed = 500)
```

```{r}
summary(imputed_Data)
```

inspeccionamos la calidad de las imputaciones 
```{r}
mice::stripplot(imputed_Data, loudness, pch = 19, xlab = "Imputation number")
```

veiem que els valors imputats no son massa diferents als valors originals, ho podem anar comprovant variable per varibale i aixi saber si ha sigut un bon metode per imputar

```{r}
completeData <- mice::complete(imputed_Data, action = "long")
completeData$time_signature_cat <- NULL

# Eliminar columnes .id i .imp si existeixen
completeData <- completeData[, !names(completeData) %in% c(".id", ".imp")]

summary(completeData)
```

donem per bona la imputació per mice. ara haurem de passar a la imputació de les variables categoriques 

Afeguim la bbdd total que tenim per ara.
```{r}
# Identificar columnes numèriques que existeixen a completeData
num_cols <- intersect(names(train)[sapply(train, is.numeric)], names(completeData))

# Substituir només aquestes columnes
train[, num_cols] <- completeData[, num_cols, drop = FALSE]

# Comprovar resultat
str(train)
summary(train)
```

# Categoriques

per poder començar haurem de convertir la variable time_signature_cat a categorica, ja que no esta ben cpnvertida en el data

```{r}
train[] <- lapply(train, function(x) {
  if (is.character(x)) as.factor(x) else x
})

if (!is.factor(train$time_signature_cat)) {
  train$time_signature_cat <- as.factor(train$time_signature_cat)
}

train_num <- train
train_num[] <- lapply(train_num, function(x) {
  if (is.factor(x)) as.numeric(x) else x
})

str(train)
summary(train)
```
# MissForest
```{r}
library(missForest)

# Preparar train: factors i numèriques
train_mf <- train  # copia del dataset

# Si tens variables numèriques ja imputades amb MICE, les pots deixar com a estàtiques
# missForest omplirà només els NA que queden (incloses les categòriques)

# Imputació amb missForest
set.seed(123)  # per reproducibilitat
imputed <- missForest(train_mf, verbose = TRUE)

# Obtenir dataset imputat
data_final <- imputed$ximp

# Comprovar que no queden NA
colSums(is.na(data_final))
str(data_final)
summary(data_final)

```

#KNN - NO funciona triga molt a fer-se
```{r, eval=FALSE}
library(caret)

# Factors a imputar
factor_cols <- names(train)[sapply(train, is.factor)]

# Només factors amb NA
factor_na <- factor_cols[colSums(is.na(train[, factor_cols, drop = FALSE])) > 0]

# Convertir factors a numèric
train_num <- train[, factor_na, drop = FALSE]
train_num[] <- lapply(train_num, as.numeric)

# Seleccionar predictors numèrics rellevants (reduït per velocitat)
num_preds <- names(completeData)[1:min(5, ncol(completeData))]  # p. ex. 5 predictors més importants
data_knn <- cbind(train_num, completeData[, num_preds, drop = FALSE])

# KNN imputació
preProc <- preProcess(data_knn, method = "knnImpute", k = 3)
imputed <- predict(preProc, newdata = data_knn)

# Tornar factors originals
for(col in factor_na){
  n_levels <- length(levels(train[[col]]))
  x <- round(imputed[[col]])
  x[x < 1] <- 1
  x[x > n_levels] <- n_levels
  imputed[[col]] <- factor(x, levels = 1:n_levels, labels = levels(train[[col]]))
}

# Substituir factors imputats al train
train[, factor_na] <- imputed[, factor_na, drop = FALSE]

# Comprovar
colSums(is.na(train[, factor_na]))

```

Anem a mirar si hi ha coherència amb els valors imputats:

```{r}
colSums(is.na(data_final))
```
No tenim cap variable amb NA's

Numeriques, mirem les distribucions (CREC QUE NO FA FALTA)
```{r}
numeric_cols <- names(data_final)[sapply(data_final, is.numeric)]

# Histogrames comparant abans i després (si tens el dataset original)
par(mfrow=c(2,2))  # per veure diversos gràfics junts
for(col in numeric_cols){
  hist(train[[col]], main=paste(col, "original"), col="lightblue")
  hist(data_final[[col]], main=paste(col, "imputat"), col="pink")
}

```
Veiem que en comparacio amb amb el original amb el que tenim no canvia gaire

Categoriques mirem distribucions
```{r}
factor_cols <- names(train)[sapply(train, is.factor)]

for(col in factor_cols){
  print(col)
  print(table(train[[col]], useNA = "ifany"))  # abans
  print(table(data_final[[col]]))              # després
}

```
Les dues últimes variables no se si acaba de ser del tot cohorent.

Fem export de les dades finals
```{r}
write.csv(data_final, "train_mis.csv", row.names = FALSE)
```

