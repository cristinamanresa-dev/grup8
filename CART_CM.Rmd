---
title: "CART"
author: "Cristina Manresa Ponsa"
date: "2025-11-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Primerament preparem les nostres dades, on les variables categòriques han de ser factors.
```{r}
train_original <- read.csv("train_pre.csv")
test_original <- read.csv("test_pre.csv")
colSums(is.na(train_original))
colSums(is.na(test_original))
str(train_original)
str(test_original)


# conversio a factors
train_original[sapply(train_original, is.character)] <- lapply(train_original[sapply(train_original, is.character)], as.factor)
test_original[sapply(test_original, is.character)] <- lapply(test_original[sapply(test_original, is.character)], as.factor)

str(train_original)
str(test_original)

set.seed(1234)
ind <- sample(1:nrow(train_original), 0.7*nrow(train_original))
train <- train_original[ind,]
test  <- train_original[-ind,]

colSums(is.na(train))
colSums(is.na(test))

# descriptiva
library(skimr)
skim(train)
skim(test)
```
> Fer comentaris sobre el que surt als skims. Pero es dedueix que una valors incials per fer el arbre seria 10 i 20, (5,10|20,40|30,60)

# CART
# Generem el arbre amb el paquet tree (no acaba de estar be)
```{r}
# apliquem una llavor perque sempre ens surti el mateix
set.seed(123)

# install.packages("tree")
library(tree)
arbol_regresion <- tree::tree(
  formula = song_popularity ~ .,
  data    = train,
  split   = "deviance", # perque estem fent regressio, l'altre opcio es gini i nomes es per classificacio
  mincut  = 10, # ns si comencem amb valors arbitraris
  minsize = 20 # ns si comencem amb valors arbitraris
)

summary(arbol_regresion)
```
> Nomes surt una variable

Intentem maximitzar la mida de l'arbre
```{r}
arbol_regresion <- tree(
  formula = song_popularity ~ .,
  data    = train,
  split   = "deviance",
  mincut  = 5,
  minsize = 10,
  mindev  = 0
)
summary(arbol_regresion)

cv_arbol <- cv.tree(arbol_regresion, K = 5)
size_optimo <- rev(cv_arbol$size)[which.min(rev(cv_arbol$dev))]
paste("Optimal size:", size_optimo)
```
> Per tant, l'arbre amb 1 split (2 nodes terminals) és suficient segons CV. Les altres variables no milloren la predicció.

Podem l'arbre
```{r}
arbol_final <- prune.tree(
  tree = arbol_regresion,
  best = size_optimo)

summary(arbol_final)
```
> jo crec que es un arbre molt petit, pero ns?

Fem les prediccions de l'arbre incial
```{r}
predicciones_train <- predict(arbol_regresion, newdata = train)
predicciones_test <- predict(arbol_regresion, newdata = test)
rmse_test    <- sqrt(mean((predicciones_test - test$song_popularity)^2))
paste("Root mean squared error (rmse) initial tree:", round(rmse_test,2))
```

Prediccions per l'arbre final
```{r}
predicciones <- predict(arbol_final, newdata = train)
predicciones_test <- predict(arbol_final, newdata = test)
rmse    <- sqrt(mean((predicciones_test - test$song_popularity)^2))
paste("rmse final tree:", round(rmse,2))
```
Export del fitxer
```{r}
prediccions_tree <- data.frame(
  id = 1:nrow(test_original),
  song_popularity = round(predict(arbol_final, test_original))
)
table(prediccions_tree$song_popularity)

# Exportar a CSV
write.csv(prediccions_tree, "prediccions_tree.csv", row.names = FALSE)

```


Fem els càlculs dels error directemanet
```{r}
caret::postResample(predicciones, test$song_popularity)
```

```{r}
accuracy <- function(pred, obs, na.rm = FALSE, 
                     tol = sqrt(.Machine$double.eps)) {
  # Filtrar NA
  if(na.rm) {
    is.a <- !is.na(obs) & !is.na(pred)
    obs <- obs[is.a]
    pred <- pred[is.a]
  }
  
  # Filtrar zeros en els valors reals
  nonzero <- obs != 0
  obs <- obs[nonzero]
  pred <- pred[nonzero]
  
  err <- obs - pred     # Errors
  if(na.rm) {
    is.a <- !is.na(err)
    err <- err[is.a]
    obs <- obs[is.a]
  }  
  perr <- 100*err/pmax(obs, tol)  # % errors
  return(c(
    me = mean(err),           # Mean error
    rmse = sqrt(mean(err^2)), # sqrt mean squared error
    mae = mean(abs(err)),     # mean absolute error
    mpe = mean(perr),         # mean percentage error
    mape = mean(abs(perr)),   # mean absolute percentage error
    r.squared = 1 - sum(err^2)/sum((obs - mean(obs))^2)
  ))
}
accuracy(predicciones, test$song_popularity)
```
> dona una prediccio pitjor

# Amb la funció rpart()
Creem el arbre
```{r}
library(rpart)
# install.packages("rpart.plot")
library(rpart.plot)
# install.packages("rattle")
library(rattle)

tree <- rpart(song_popularity ~., data = train)
tree
summary(tree)
```
> és un arbre molt simple, nomes es un surt una varibale, poca capacitat predictiva perque perdem dades i no expendim el arbre.

Grafiquem 
```{r}
windows()
rpart.plot(tree) # per defecte
rpart.plot(tree,type=0) # nomes les caixes
rpart.plot(tree,type=1) # caixes + etiquetes laterals
rpart.plot(tree,type=2) # caixes sota cada node
rpart.plot(tree,type=5) # estil mes compacte
```


```{r}
# l'arbre en regles
rpart.rules(tree, style = "tall")
tree$variable.importance
```
> El teu model CART diu que la popularitat d’una cançó es pot predir sobretot segons loudness_energy_impact, i gairebé només amb aquesta variable.
La resta d’atributs tenen molt poca influència en el model.

### Busquem millor arbre amb la estrategia den Dante, cp=0
```{r}
set.seed(1234)
tree <- rpart(song_popularity ~ ., data = train, cp = 0) 

printcp(tree) # li demanem les validacions creuades
plotcp(tree)
xerror <- tree$cptable[,"xerror"]
xerror
imin.xerror <- which.min(xerror)
imin.xerror # es la posiccio
tree$cptable[imin.xerror, ]
upper.xerror <- xerror[imin.xerror] + tree$cptable[imin.xerror, "xstd"]
upper.xerror
tree <- prune(tree, cp = 0.001663718) 
rpart.plot(tree)
```
> Es veu que el millo cp optim és en la posicio 15, que es 0.001765578

```{r}
importance <- tree$variable.importance
importance <- round(100*importance/sum(importance), 1)
importance
```
> La popularitat de la cançó depèn principalment del nivell d’energia i loudness, i de com interaccionen amb el ball/ritme (energy_dance_synergy).
Altres factors musicals i de dansa aporten moderadament.
Les variables restants pràcticament no influeixen en les decisions de l’arbre (les que son 1 o menys).
L’arbre confirma que la percepció de la cançó com a energètica i “ballable”, combinada amb aspectes de volum i interaccions musicals, és el factor clau per la seva popularitat. La resta de característiques són menys rellevants.

### Evaluem el model
```{r}
library(rpart)

# Assegura’t que song_popularity és numèrica
train$song_popularity <- as.numeric(train$song_popularity)
test$song_popularity  <- as.numeric(test$song_popularity)

tree <- rpart(song_popularity ~ ., data = train, method = "anova", cp = 0.0018)

```


```{r}
# Prediccions
p_train <- predict(tree, train)
p_test  <- predict(tree, test)

(mse_train <- mean((p_train - train$song_popularity)^2))
(rmse_train <- sqrt(mse_train))

(mse_test <- mean((p_test - test$song_popularity)^2))
(rmse_test <- sqrt(mse_test))

(mape_train <- mean(abs((train$song_popularity - p_train) / pmax(train$song_popularity, 1e-5))) * 100)
(mape_test  <- mean(abs((test$song_popularity - p_test) / pmax(test$song_popularity, 1e-5))) * 100)

(smape_train <- mean(2 * abs(p_train - train$song_popularity) / (abs(train$song_popularity) + abs(p_train))) * 100)
(smape_test  <- mean(2 * abs(p_test - test$song_popularity) / (abs(test$song_popularity) + abs(p_test))) * 100)

```
Export del fitxer
```{r}
prediccions_rpart <- data.frame(
  test_original$ID,
  song_popularity = round(predict(tree, test_original))
)
table(prediccions_tree$song_popularity)

# Exportar a CSV
write.csv(prediccions_rpart, "prediccions_rpart.csv", row.names = FALSE)

```

# Un altre metode: CARET
```{r}
library(caret)
library(rpart.plot)

# Definim el control de CV
ctrl <- trainControl(method = "cv", number = 10,
                     selectionFunction = "oneSE")

# Entrenem l'arbre de regressió
caret.rpart <- train(song_popularity ~ ., 
                     data = train,
                     method = "rpart",
                     tuneLength = 20, 
                     trControl = ctrl)

# Visualitzem l'evolució de l'error segons CP
ggplot(caret.rpart)
```


```{r}
# Veiem l'arbre final podat
rpart.plot(caret.rpart$finalModel)

# Importància de les variables
var.imp <- varImp(caret.rpart)
plot(var.imp)
```


```{r}
# Prediccions sobre train i test
pred_train <- predict(caret.rpart, newdata = train)
pred_test  <- predict(caret.rpart, newdata = test)
pred_train_int <- round(pred_train)
pred_test_int  <- round(pred_test)

# Errors
mse_train <- mean((pred_train - train$song_popularity)^2)
rmse_train <- sqrt(mse_train)

mse_test <- mean((pred_test - test$song_popularity)^2)
rmse_test <- sqrt(mse_test)

nonzero_idx_train <- train$song_popularity != 0
mape_train <- mean(abs((train$song_popularity[nonzero_idx_train] - pred_train[nonzero_idx_train]) / 
                       train$song_popularity[nonzero_idx_train])) * 100

nonzero_idx_test <- test$song_popularity != 0
mape_test <- mean(abs((test$song_popularity[nonzero_idx_test] - pred_test[nonzero_idx_test]) / 
                      test$song_popularity[nonzero_idx_test])) * 100

mse_train; rmse_train
mse_test; rmse_test
mape_train; mape_test

epsilon <- 1e-6
mape_train <- mean(abs((train$song_popularity - pred_train) / (train$song_popularity + epsilon))) * 100
mape_test <- mean(abs((test$song_popularity - pred_test) / (test$song_popularity + epsilon))) * 100

mape_train; mape_test
```

Fem les prediccions per test_original
```{r}
pred_nou <- predict(caret.rpart, test_original)
pred_nou <- round(pred_nou)


prediccions_caret <- data.frame(
  id = 1:nrow(test_original),
  song_popularity = pred_nou
)
table(prediccions_caret$song_popularity)

# Exportar a CSV
write.csv(prediccions_caret, "prediccions_caret.csv", row.names = FALSE)

```

# C4.5 ARBRE