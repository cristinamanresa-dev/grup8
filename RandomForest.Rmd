---
title: "RandomForest"
author: "Cristina Manresa"
date: "2025-11-10"
output: html_document
---
Preparacio de les dades, treient duplicats una altra vegada i despres mira quines variables tenen mes outliers per prescindir d'elles
```{r}
library(readr)
train <- read_csv("train_pre.csv")
test <- read_csv("test_pre.csv")
```

Fem una previa visualització de les dades
```{r}
# install.packages("dlookr")
library(dlookr)
dlookr::diagnose(train)
head(overview(train), n = 9)
```
Ara per test,
```{r}
library(dlookr)
dlookr::diagnose(test)
head(overview(test), n = 9)
```

(laia: a mi si que em surten observacions duplicades, 32 en el train i 2 en el test)

eliminem les observacions duplicades
```{r}
train <- train[!duplicated(train),]
```



Anem a detctar els outliers
```{r}
library(dplyr)

(num <- diagnose_numeric(train) %>% select(variables, outlier))
(cat <- diagnose_category(train))
```
Veiem que tenim diferents variables numériques amb outliers, la que destaca mes és la variable speechniess. També tenim song_duration_min (633), loudness (481), loudness_energy_impact (346) i danceability (69) que haurem de estudiar mes detalladament.

Es detecten outliers en variables numèriques i es revisen variables categòriques. Es veu que speechiness té molts outliers, seguit de song_duration_min, loudness, loudness_energy_impact i danceability. Això suggereix que potser caldrà treure o transformar aquestes variables.

Ho fem per test
```{r}
library(dplyr)

(num_test <- diagnose_numeric(test) %>% select(variables, outlier))
(cat_test <- diagnose_category(test))
```
Veiem que tenim diferents variables numériques amb outliers, la que destaca mes és la variable speechniess. També tenim song_duration_min (204), loudness (240), loudness_energy_impact (165) i d'altres amb menys nombre d'outliers.

Eliminem les variables amb masses outliers
```{r}
library(dplyr)
library(readr)

vars_remove <- c("speechiness", "song_duration_min", "loudness", "loudness_energy_impact")

train_f <- train %>% select(-all_of(vars_remove))
test_f  <- test  %>% select(-all_of(vars_remove))

```
S'eliminen les variables amb més outliers per reduir el seu impacte en els models. Es creen nous conjunts train_f i test_f sense aquestes variables.

# Primera proposta
```{r}
library(randomForest)
library(Metrics)   # per RMSE

set.seed(123)

# Entrenar RF sense variables problemàtiques
rf_model <- randomForest(song_popularity ~ ., data = train_f, ntree = 200)

# Predicció sobre train per calcular RMSE (validació simple)
pred_train <- predict(rf_model, train_f)

rmse_value <- rmse(train_f$song_popularity, pred_train)
rmse_value

pred_test <- predict(rf_model, test_f)

pred_test <- as.integer(pmin(pmax(round(pred_test), 0), 100))

results <- data.frame(ID = seq_len(nrow(test_f)), song_popularity = pred_test)
write.csv(results, "predictions_RF.csv", row.names = FALSE)
table(results$song_popularity)
```
 Primer model de Random Forest. Es calcula RMSE sobre train (pot ser optimista). Les prediccions es retallen entre 0 i 100. Es guarden els resultats i es mostra la distribució de les prediccions.

# Nova versio
Provant d'eliminar totes les variables amb outliers significatius
```{r}
vars_remove <- c("speechiness", 
                 "song_duration_min",
                 "loudness",
                 "loudness_energy_impact",
                 "danceability")
```

Es tornen a carregar les dades originals i es creen conjunts nets sense les variables problemàtiques.
```{r}
library(readr)
library(dplyr)
library(randomForest)
library(xgboost)
library(Metrics)

train_data <- read_csv("train_pre.csv")
test_data  <- read_csv("test_pre.csv")

train_clean <- train_data %>% select(-all_of(vars_remove))
test_clean  <- test_data %>% select(-all_of(vars_remove))
```


Es divideix el conjunt de train en 80% entrenament i 20% validació per avaluar millor els models abans de fer la predicció final.
```{r}
# Split train/validation
set.seed(123)
n <- nrow(train_clean)
idx <- sample(seq_len(n), size = floor(0.8*n))

train_split <- train_clean[idx, ]
val_split   <- train_clean[-idx, ]
```

Fem RF i calcul de RMSE
```{r}
# Random Forest
rf_model <- randomForest(
  song_popularity ~ ., 
  data = train_split,
  ntree = 300
)

rf_pred <- predict(rf_model, val_split)
rf_rmse <- rmse(val_split$song_popularity, rf_pred)
rf_rmse
```
S'entrena un Random Forest i s'avalua sobre el conjunt de validació. RMSE ≈ 20 és alt, indicant que el model no prediu amb molta precisió.
Dona un valor de 20, hauria de ser mes baix

Provem amb XgBOOST
```{r}
# XGBoost
X_train <- model.matrix(song_popularity ~ . - 1, data = train_split)
y_train <- train_split$song_popularity

X_val   <- model.matrix(song_popularity ~ . - 1, data = val_split)
y_val   <- val_split$song_popularity

xgb_model <- xgboost(
  data = X_train,
  label = y_train,
  nrounds = 300,
  objective = "reg:squarederror",
  eta = 0.05,
  max_depth = 6,
  verbose = 0
)

xgb_pred <- predict(xgb_model, X_val)
xgb_rmse <- rmse(y_val, xgb_pred)
xgb_rmse

```
Prova amb XGBoost. RMSE encara més elevat, fet que suggereix que aquesta configuració no millora les prediccions.

Els models han arribat a un limit de predictibilitat amb les caracteristiques actuals.

Prediccions amb les dades netes i originals
```{r}
# Entrenament final amb totes les dades netes
rf_final <- randomForest(song_popularity ~ ., 
                         data = train_clean, 
                         ntree = 300)

pred <- predict(rf_final, test_clean)
pred <- as.integer(pmin(pmax(round(pred), 0), 100))

results <- data.frame(
  ID = seq_len(nrow(test_clean)),
  song_popularity = pred
)

write.csv(results, "predictions_RF_2.csv", row.names = FALSE)
table(results$song_popularity)
```
Ens dona millor la primera versio, quan ho pujem a Kaggle

# Seguint Script de Classe
Lleguim les dades i fem la particio
S'inicia un nou enfoc basat en scripts de classe. Es tornen a eliminar variables i es divideix train en 70%-30%.
```{r}
vars_remove <- c("speechiness",
                 "song_duration_ms",
                 "loudness",
                 "loudness_energy_impact",
                 "danceability")
library(readr)
dades_train <- read.csv("train_pre.csv")
dades_test  <- read.csv("test_pre.csv")

dades_train <- dades_train[ , !(names(dades_train) %in% vars_remove)]
dades_test  <- dades_test[  , !(names(dades_test)  %in% vars_remove)]

set.seed(123)
id <- sample(1:nrow(dades_train), 0.7*nrow(dades_train))
train <- dades_train[id,]
test  <- dades_train[-id,]
```

## Using RANGER PACKAGE
```{r}
library(ranger)
require(utils)
param_grid = expand.grid(num_trees = c(50, 100, 500, 1000),
             mtry= c(3, 5, 7, ncol(train)-1),max_depth = c(3, 10, 20))
oob_error = rep(NA, nrow(param_grid))
```

Ajustar un modelo con hiperparamatros, en triga molt i ns si es necesari
```{r}


for(i in 1:nrow(param_grid)){
  
  modelo <- ranger(
    formula   = song_popularity ~ .,
    data      = train, 
    num.trees = param_grid$num_trees[i],
    mtry      = param_grid$mtry[i],
    max.depth = param_grid$max_depth[i],
    seed      = 123
  )
  
  oob_error[i] <- sqrt(modelo$prediction.error) # RMSE OOB
}
```

Els resultats
```{r}
library(dplyr)

resultados <- param_grid
resultados$oob_error <- oob_error

resultados <- resultados %>% arrange(oob_error)
print(resultados)

#MILLOR MODEL
resultados[1, ]
```

Model final, substituint els millors valors que hagin sortit millors
```{r}
set.seed(123)
modelo_final <- ranger(
  formula = song_popularity ~ .,
  data = train,
  num.trees = resultados$num_trees[1],
  mtry = resultados$mtry[1],
  max.depth = resultados$max_depth[1],
  importance = "impurity",
  seed = 123
)

```

Prediccions sobre el test
```{r}
pred_test <- predict(modelo_final, data = test)$predictions

# calcul del RMSE i demes KPIs
caret::postResample(pred_test, test$song_popularity)

accuracy <- function(pred, obs, na.rm = FALSE, 
                     tol = sqrt(.Machine$double.eps)) {
  err <- obs - pred  
  if(na.rm) {
    is.a <- !is.na(err)
    err <- err[is.a]
    obs <- obs[is.a]
  }
  perr <- 100*err/pmax(obs, tol)
  return(c(
    me = mean(err),
    rmse = sqrt(mean(err^2)),
    mae = mean(abs(err)),
    mpe = mean(perr),
    mape = mean(abs(perr)),
    r.squared = 1 - sum(err^2)/sum((obs - mean(obs))^2)
  ))
}

accuracy(pred_test, test$song_popularity)

```

Predicció final per penjar el Kaggle
```{r}
pred_final <- predict(modelo_final, data = dades_test)$predictions
pred_final <- as.integer(pmin(pmax(round(pred_final), 0), 100))

results <- data.frame(
  ID = seq_len(nrow(dades_test)),
  song_popularity = pred_final
)

write.csv(results, "predictions_RFClasse.csv", row.names = FALSE)
table(results$song_popularity)
```
es la pitjor

## Con Caret

Tornem a llegir les dades
```{r}
library(readr)
library(dplyr)
library(caret)
library(randomForest)

# 1. Variables a eliminar
vars_remove <- c("speechiness",
                 "song_duration_min",
                 "loudness",
                 "loudness_energy_impact",
                 "danceability")

# 2. Carregar dades
dades_train <- read.csv("train_pre.csv")
dades_test  <- read.csv("test_pre.csv")

# 3. Eliminar variables amb outliers
dades_train <- dades_train[ , !(names(dades_train) %in% vars_remove)]
dades_test  <- dades_test[  , !(names(dades_test)  %in% vars_remove)]

# 4. Partició Train/Test del *train*
set.seed(123)
id <- sample(1:nrow(dades_train), 0.7 * nrow(dades_train))
train <- dades_train[id, ]
test  <- dades_train[-id, ]
```

```{r}
library(doParallel)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)


param_grid = expand.grid(
  mtry = c(3, 5, 7, ncol(train) - 1)
)

train_ctrl <- trainControl(
  method = "cv",
  number = 5
)

#triga moltissim
model_cv_grid <- train(
  song_popularity ~ .,
  data = train,
  method = "rf",
  metric = "RMSE",
  trControl = train_ctrl,
  tuneGrid = param_grid,
  ntree = 1000, # Recomana a Classe prova amb 1000 o 5000 i mira quin es millor
  importance = TRUE
)

print(model_cv_grid)
plot(model_cv_grid)

stopCluster(cl)

```
> d'aqui hem de veure amb quin nombre d'arbres ho hem de fer i despres mirar el millor mtry

Model final amb millor mtry
```{r}
best_mtry <- model_cv_grid$bestTune$mtry
best_mtry

model_final <- randomForest(
  song_popularity ~ .,
  data = train,
  ntree = 100,
  mtry = best_mtry,
  importance = TRUE
)

varImpPlot(model_final)

```

Prediccions i RMSE
```{r}
pred <- predict(model_final, test)

# Clamp 0–100
pred <- as.integer(pmin(pmax(round(pred), 0), 100))

# RMSE
rmse <- sqrt(mean((pred - test$song_popularity)^2))
rmse
```

Apliquem per penjar al Kaggle
```{r}
pred_test <- predict(model_final, dades_test)
pred_test <- as.integer(pmin(pmax(round(pred_test), 0), 100))

results <- data.frame(
  ID = seq_len(nrow(dades_test)),
  song_popularity = pred_test
)

write.csv(results, "predictions_RFClasse2.csv", row.names = FALSE)
table(results$song_popularity)
```

#CONCLUSIO DELS METODES

##COMPARATIVA DE MÈTODES
Resultat Observat: Random Forest > XGBoost > Ranger tuning

Conclusió Profunda:

Random Forest funciona bé out-of-the-box per a aquest problema

XGBoost necessita tuning intensiu i no millora automàticament

Hiperparàmetre tuning dóna millores marginals (19.83 vs 20.16)

Interpretació: Les dades no tenen relacions complexes no-lineals que XGBoost exploti millor que RF. El problema és més de feature limitation que de model limitation.

##DISTRIBUCIÓ DE PREDICCIONS
Resultat Observat: Prediccions concentrades entre 24-45, poques extremes.

Conclusió Profunda:
El model està excessivament conservador i no s'aventura a predir valors alts (70-100) o molt baixos (0-20). Això suggereix:

Pèrdua d'informació dels outliers eliminats

Models lineals implícits que converteixen tot a mitjanes

Falta de captura de patrons no lineals

#random forest amb caret
```{r}
#caret nou

# Carregar paquets necessaris
library(caret)
library(randomForest)

# Definir variables predictives i variable objectiu
set.seed(123)  # Per reproductibilitat
trainIndex <- createDataPartition(train$song_popularity, p = 0.8, list = FALSE)
trainData <- train[trainIndex, ]
testData <- train[-trainIndex, ]

# Definir control de entrenament amb validació creuada
fitControl <- trainControl(method = "cv",  # Cross-validation
                           number = 5)     # 5 folds

# Entrenar model Random Forest
rf_model <- train(song_popularity ~ ., 
                  data = trainData,
                  method = "rf",
                  trControl = fitControl,
                  tuneLength = 5)  # Número de valors mtry a provar

# Veure resum del model
print(rf_model)

# Predicció sobre dades de test
predictions <- predict(rf_model, newdata = testData)

# Avaluar errors
postResample(pred = predictions, obs = testData$song_popularity)

```

